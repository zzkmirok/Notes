# CS 285
# Lecture 2
## Terminology & Notation
- State(Fully observed), Observation and Action.
- Policy
- **Markov property**
    $$
    \pi(a_t|s_t)
    $$

## Imitation Learning
- not possible
**Underlying Math Principle**
Distribution over observation are different (because of taking different policy and generating $P_{\pi_\theta}(o_t)$)
> Distributional shift

**Solutions**

--->

### Why might we fail to fit the expert
- Non Markov behaviour
- Multimodal behaviour
**Solution for 2**
1. Mixture of Gaussians
2. latent variable models (Important)
3. Diffusion models
4. Autogressive Discretization
   - Sequence model ---> vetorized distribution with linear increase of number of blocks (nn output).
  

### Multitask Learning
- Goal-Conditioned Behavioral cloning
  > Distributional shift in multiple destination

### DAgger: Dataset Aggregation
- train from an Episode (original human dataset)
- state evaluation (run the policy)
- policy improvement (human labelling)
- Data set Aggregation to new dataset. Go to 1.
- 
  
## What RL solve?
$$
min_{\theta}E_{a \sim \pi_{\theta}(a|s),s' \sim p(s'|s,a)}[\delta(s' = \text{some states})]
$$

# Lecture 3: Numpy + Pytorch
## Numpy shape Note
### How to keep the track of the expected shape of each array refer to:
 * Asserts (`assert x.shape == (batch_size, hidden_dim)`)
 * Comments (`# shape (B, C, W, H)`)
 * Fancier typechecking libraries (`jaxtyping`, `torchtyping`, etc.)

### Benefits of `squeeze` and `np.newaxis`

```python
a = np.random.randint(10, size=(10, 1, 4, 1, 1, 6, 2))
print(a.shape)
print(a.reshape(10, 4, 1, 6, 2).shape)
print(a.squeeze((1, 3)).shape)
```

```python
b = np.random.randint(10, size=(10, 4, 2, 7, 8, 9))
print(b.shape)
print(b.reshape(10, 1, 4, 1, 2, 7, 8, 9).shape)
print(b[:, np.newaxis, :, np.newaxis, ...].shape) # ... means "rest of dimensions"
```

> Note:
> `...` means rest of dimensions

## Automatic differentiation
### `requires_grad=True`
* By default, tensors have requires_grad=False. Need to specify if you want the gradients for a tensor!
```python
shape = (3, )
x = torch.tensor([1., 2, 3], requires_grad=True)
y = torch.ones(shape, requires_grad=True)
```

### `grad_fn`
Notice the `grad_fn` property on the tensor. We can trace our way back through these grad functions to see the whole computation graph:
```python
grad_fns = [(loss.grad_fn, 0)]
curr_level = 0
lines = []
while grad_fns:
    prev_level = curr_level
    fn, curr_level = grad_fns.pop()
    if curr_level != prev_level:
        print("---")
    print(fn.name())
    for next_fn, _ in fn.next_functions:
        if next_fn:
            grad_fns.append((next_fn, curr_level + 1))
```
 
### A few things to watch out for:
  - You can't do any in-place operations on a tensor that has `requires_grad=True`. (This prevents you from inadvertently mutating it in a way that isn't tracked for backprop purposes.)

  - You also can't convert a tensor with `requires_grad=True` to numpy (for the same reason as above). Instead, you need to detach it first, e.g. `y.detach().numpy()`.

  - Even though `y.detach()` returns a new tensor, that tensor occupies the same memory as `y`. Unfortunately, PyTorch lets you make changes to `y.detach()` or `y.detach.numpy()` which will affect `y` as well! If you want to safely mutate the detached version, you should use `y.detach().clone()` instead, which will create a tensor in new memory.

### RL Connection: 
You would want to be doing simulator-related tasks with numpy, convert to torch when doing model-related tasks, and convert back to feed output into simulator.

## Modules
* `nn.Module` represents the building blocks of a computation graph.
For example, in typical pytorch code, each convolution block above is its own module, each fully connected block is a module, and the whole network itself is also a module.
* Modules can contain modules within them.
* All the classes inside of `torch.nn` are instances `nn.Modules`.

### Example Definition of a module
```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    def __init__(self, input_size, output_size):
        super(Net, self).__init__()
        self.net = nn.Sequential()
        self.fc1 = nn.Linear(input_size, 32)
        self.fc2 = nn.Linear(32, 32)
        self.fc3 = nn.Linear(32, output_size)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
```
Note: In the `__init__` function, any variable that you assign to `self` that is also a module will be automatically added as a sub-module. The parameters of a module (and all sub-modules) can be accessed through the `parameters()` or `named_parameters()` functions:

```python
for name, p in net.named_parameters():
    print(name, p.shape)
```

> Warning:
> if you want to have a list of modules use
```python
def __init__(self, network1, network2):
    self.list = nn.ModuleList([network1, network 2])
```
### Another Example:
`nn.Sequential` can be called and evaluted directly.
```python
import torch.nn as nn
class SingleLayerNetwork(nn.Module):
    def __init__(self, in_dim: int, out_dim: int, hidden_dim int):
        super().__init__()# <--Do not forget this!
        self.net = nn.Sequential(
            nn.Module(in_dim, hidden_dim),
            nn.ReLU(),
            nn.Module(hidden_dim, out_dim),
        )
    
    def forward(self, x: torch.Tensor) -> Torch.Tensor:
        return self.net(x)
```

### Manually Training

We can manually update the parameters by adding the gradient (times a negative learning rate) and zero'ing out the gradients to prevent gradient accumulation.

```python
for p in net.parameters():
    p.data.add_(-0.001 * p.grad)
    p.grad.data.zero_()
```
**Manually Training**
```python
for _ in range(100):
    y = net(x)
    loss = ((y - y_target)**2).sum()
    loss.backward()
    for p in net.parameters():
        p.data.add_(- 0.001 * p.grad)
        p.grad.data.zero_()
```

## Optimizers

```python
from torch import optim

net = Net(input_size=1, output_size=1)

optimizer = optim.Adam(net.parameters(), lr=1e-3) # or SGD, RMSProp

x = torch.linspace(-5, 5, 100).view(-1, 1)
y = net(x)
y_target = torch.sin(x)
loss_fn = nn.MSELoss()
```
### How to train
here's how you can use the optimize to train the network.
Note that we call `zero_grad` _before_ calling `loss.backward()`, and then we just call `optimizer.step()`. This `step` function will take care of updating all the parameters that were passed to that optimizer's constructor.
****
```python
for _ in range(100):
    y = net(x)
    loss = loss_fn(y, y_target)

    optimizer.zero_grad() # zero's out gradients
    loss.backward() # populate gradients
    optimizer.step() # update each parameter via gradient descent
```

To summarize, here's what we did:

- Defined a class for our neural network (subclass of `nn.Module`)
- Specified a loss function (MSE loss) and optimizer (Adam) --> make sure to pass all model parameters (especially for multimodal)
- Performed training by doing the following in a loop:
    - Make prediction
    - Compute loss
    - Zero the stored gradients
    - Backprop the loss with `.backward()`
    - Update the weights by taking a step of gradient descent


## Evaluationg the model
Notice the `.eval()` and `with torch.no_grad()` -- make sure to include these whenever making predictions at test time!
```python
net.eval() # Switches the network to evaluation mode, disabling things like dropout and batch norm
with torch.no_grad(): # Temporarily disables all `requires_grad` within the enclosed block
    y = net(x)
plot(x.cpu().numpy(), y.cpu().numpy())
```

## Save and Load model weights
```python
# Save a dictionary of parameter names and their values
PATH = "checkpoint.pt"
torch.save(net.state_dict(), PATH)
# saves everything including parameters and other state values (i.e. batch norm mean)
```

```python
# Later: Initialize a new model and load the saved state dict
new_model = Net(input_size=1, output_size=1) # with same architecture
new_model.to(device)
new_model.load_state_dict(torch.load(PATH))
new_model.eval()

for (name1, val1), (name2, val2) in zip(net.state_dict().items(), new_model.state_dict().items()):
    assert name1 == name2 and torch.equal(val1, val2), f"{name1} and {name2} states differ!"
```

## Distributions
```python
# Univariate Gaussian with mean 0, std 1
mean = torch.zeros(1, requires_grad=True)
std = torch.ones(1, requires_grad=True)
gaussian = distributions.Normal(mean, std)
```
The two most useful operations you can do with `Distribution` objects are `sample` and `log_prob`:
```python
sample = gaussian.sample((1,))
print(sample)
```
```python
log_prob = gaussian.log_prob(sample)
```

The log probability depends on the the parameters of the distribution. So, calling `backward` on a loss that depends on `log_prob` will back-propagate gradients into the parameters of the distribution.

**NOTE**: this won't back-propagate through the samples (the "reparameterization trick''), unless you use `rsample`, which is only implemented for some distributions.

### Understanding Distribution Shapes
```python
mean = torch.zeros(2)
covariance = torch.tensor(
    [
     [[1, 0.8],
     [0.8, 2]],
     [[1, -0.2],
      [-0.2, 1]],
     [[4, 0.6],
      [0.6, 0.5]]
    ]
)
gaussian = distributions.MultivariateNormal(mean, covariance)
sample = gaussian.sample((5,))

print(gaussian.batch_shape) #torch.Size([3])
print(gaussian.event_shape) #torch.Size([2])
print(sample.shape) #torch.Size([5,3,2])
```

- **Batch shape**: The number of different (possibly non-iid) values you will sample at once.
    - Specified when initializing the distribution. In the example above, it's the number of covariance matrices we provide (3)
- **Event shape**: The shape of a single sample from one of the distributions in the batch.
    - Specified when initializing the distribution. In the example above, it's the size of our covariance matrix (2)
- **Sample shape:** The number of iid samples we take from the overall distribution.
    - Specified when calling `sample()`. In the example above, we asked for a sample shape of `(5,)`

In general, when you call `dist.sample(sample_shape)`, the result will have shape `(sample_shape, batch_shape, event_shape)`.

## Example: Training a Conditional Gaussian Model
Let's use what we've covered to train a Gaussian model:

$$\pi(a|s) \sim \mathcal{N} (f_\theta(s), \Sigma)$$

(To make this example concrete, you could imagine that we're trying to learn a policy through behavior cloning given some data from an expert. Given some state $s$, our policy will output a Gaussian action distribution $\pi(a|s)$, whose mean and standard deviation we will predict using a neural network.)

```python 
class GaussianPolicy(nn.Module):
    def __init__(self, input_size, output_size):
        super(GaussianPolicy, self).__init__()

        # Mean will be a function of input; std will be a fixed (learned) value
        self.mean_fc1 = nn.Linear(input_size, 32)
        self.mean_fc2 = nn.Linear(32, 32)
        self.mean_fc3 = nn.Linear(32, output_size)
        self.log_std = nn.Parameter(torch.randn(output_size))

    def forward(self, x):
        mean = F.relu(self.mean_fc1(x))
        mean = F.relu(self.mean_fc2(mean))
        mean = self.mean_fc3(mean)
        return distributions.Normal(mean, self.log_std.exp())
```

```python
states = torch.rand(1000, 2) - 0.5 # 1000 samples of 2-dimensional states

true_means = states**3 + 4.5*states
true_cov = torch.diag(torch.tensor([0.1, 0.05]))
expert_actions = torch.distributions.MultivariateNormal(true_means, true_cov).sample()

plt.scatter(expert_actions[:,0], expert_actions[:,1])
```
```python
from torch.utils.data import DataLoader, TensorDataset

policy = GaussianPolicy(2, 2)
optimizer = optim.Adam(policy.parameters(), lr=0.01)

dataset = TensorDataset(states, expert_actions)
loader = DataLoader(dataset, batch_size=64, shuffle=True) # gives you data in batches

losses = []
for epoch in range(200):
    epoch_loss = 0
    for curr_states, curr_actions in loader:
        dist = policy(curr_states)
        # dist = torch.distributions.Normal(mean, torch.exp(log_std))
        loss = -dist.log_prob(curr_actions).sum()

        optimizer.zero_grad()
        loss.backward()
        epoch_loss += loss.detach().cpu().numpy().squeeze()
        optimizer.step()
    losses.append(epoch_loss / len(loader)) # Calculate the decreasd epoch loss

plt.plot(losses)
```
> Update epoch loss

## Useful functions
```python
x = torch.arange(6).reshape(2, 3)
y = torch.tensor([0, 1]).reshape(2, 1)
print(x)
print(y)
print(torch.gather(x, 0, y))
```
```python
x = torch.arange(6).reshape(2, 3)
y = torch.tensor([0, 1, 0]).reshape(1, 3)
print(x)
print(y)
print(torch.gather(x, 0, y))
```

For a 3-D tensor the output is specified by::

    out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0
    out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1
    out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2
